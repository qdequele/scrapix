# Optimized Dockerfile for Fly.io deployment
# Build stage
FROM node:20-slim AS builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    make \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy package files
COPY tsconfig.base.json tsconfig.json package.json ./
COPY apps/scraper/package.json ./apps/scraper/
COPY apps/scraper/core/package.json ./apps/scraper/core/
COPY apps/scraper/server/package.json ./apps/scraper/server/
COPY apps/scraper/cli/package.json ./apps/scraper/cli/

# Install dependencies
WORKDIR /app/apps/scraper
RUN npm install --workspaces --include-workspace-root --legacy-peer-deps

# Copy source code
WORKDIR /app
COPY apps/scraper/ ./apps/scraper/

# Build the application
WORKDIR /app/apps/scraper/core
RUN npm run build

WORKDIR /app/apps/scraper/server
RUN npm run build

# Production stage
FROM node:20-slim

WORKDIR /app

# Install Chrome dependencies for Puppeteer
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    ca-certificates \
    fonts-liberation \
    libasound2 \
    libatk-bridge2.0-0 \
    libatk1.0-0 \
    libc6 \
    libcairo2 \
    libcups2 \
    libdbus-1-3 \
    libexpat1 \
    libfontconfig1 \
    libgbm1 \
    libgcc1 \
    libglib2.0-0 \
    libgtk-3-0 \
    libnspr4 \
    libnss3 \
    libpango-1.0-0 \
    libpangocairo-1.0-0 \
    libstdc++6 \
    libx11-6 \
    libx11-xcb1 \
    libxcb1 \
    libxcomposite1 \
    libxcursor1 \
    libxdamage1 \
    libxext6 \
    libxfixes3 \
    libxi6 \
    libxrandr2 \
    libxrender1 \
    libxss1 \
    libxtst6 \
    lsb-release \
    xdg-utils \
    && wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list' \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# Copy built application from builder
COPY --from=builder /app/apps/scraper/core/dist ./apps/scraper/core/dist
COPY --from=builder /app/apps/scraper/server/dist ./apps/scraper/server/dist
COPY --from=builder /app/apps/scraper/core/node_modules ./apps/scraper/core/node_modules
COPY --from=builder /app/apps/scraper/server/node_modules ./apps/scraper/server/node_modules
COPY --from=builder /app/apps/scraper/node_modules ./apps/scraper/node_modules

# Copy package.json files for proper module resolution
COPY --from=builder /app/package.json ./
COPY --from=builder /app/apps/scraper/package.json ./apps/scraper/
COPY --from=builder /app/apps/scraper/core/package.json ./apps/scraper/core/
COPY --from=builder /app/apps/scraper/server/package.json ./apps/scraper/server/

# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser \
    && mkdir -p /home/appuser/.cache \
    && chown -R appuser:appuser /app /home/appuser

USER appuser

# Environment variables
ENV NODE_ENV=production
ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/google-chrome-stable

EXPOSE 8080

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node -e "require('http').get('http://localhost:8080/health', (r) => {r.statusCode === 200 ? process.exit(0) : process.exit(1)})"

# Start the server
WORKDIR /app/apps/scraper/server
CMD ["node", "dist/index.js"]